{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "First, we'll import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll query the City of Philadelphia data via the ArcGIS REST API using the `requests` library. We'll also use the `json` library to parse the response.\n",
    "\n",
    "Finally, we'll use the `geopandas` library to create a geodataframe from the response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three different datasets to import from the City's ArcGIS server. These are:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vacant Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the Vacant_Indicators_Land feature service\n",
    "land_url = 'https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/Vacant_Indicators_Land/FeatureServer/0/query'\n",
    "\n",
    "# Define the parameters for the Vacant_Indicators_Land API request\n",
    "land_params = {\n",
    "    'where': '1=1',\n",
    "    'outFields': '*',\n",
    "    'returnGeometry': 'true',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "# Make the Vacant_Indicators_Land API request\n",
    "land_response = requests.get(land_url, params=land_params)\n",
    "\n",
    "# Check if the Vacant_Indicators_Land request was successful\n",
    "if land_response.status_code == 200:\n",
    "    # Convert the Vacant_Indicators_Land JSON data to a geopandas geodataframe; convert to CRS 2272\n",
    "    land_data = land_response.json()\n",
    "\n",
    "    # convert the JSON data to a pandas dataframe\n",
    "    land_df = pd.DataFrame(land_data['features'])\n",
    "\n",
    "    # separate the attributes column into one column per attribute\n",
    "    land_df = pd.concat([land_df.drop(['attributes'], axis=1), land_df['attributes'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # make the `geometry` column a shapely geometry object\n",
    "    land_df['geometry'] = land_df['geometry'].apply(lambda x: Polygon(x['rings'][0]))\n",
    "\n",
    "    # convert the pandas dataframe to a geopandas geodataframe\n",
    "    land_gdf = gpd.GeoDataFrame(land_df, geometry='geometry', crs='EPSG:2272')\n",
    "\n",
    "else:\n",
    "    print('Vacant_Indicators_Land Request failed with status code:', land_response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll apply string cleaning to the OWNER1 and OWNER2 columns to identify public vs. private ownership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column that combines the OWNER1 and OWNER2 columns according to the following rules:\n",
    "# if OWNER1 is not null and OWNER2 is null, then the new column is OWNER1\n",
    "# if OWNER1 is null and OWNER2 is not null, then the new column is OWNER2\n",
    "# if OWNER2 starts with a preposition, then the new column is OWNER1 + OWNER2 separated by a space\n",
    "# if OWNER2 does not start with a preposition, then the new column is OWNER2 + OWNER1 separated by a se\n",
    "\n",
    "\n",
    "# define a function to check if a string starts with a preposition\n",
    "def starts_with_preposition(string):\n",
    "    prepositions = ['a', 'an', 'and', 'as', 'at', 'but', 'by', 'for', 'from', 'in', 'into', 'nor', 'of', 'on', 'or', 'so', 'the', 'to', 'up', 'yet']\n",
    "    if string.split(' ')[0].lower() in prepositions:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# define a function to combine the OWNER1 and OWNER2 columns\n",
    "def combine_owners(row):\n",
    "    if pd.isnull(row['OWNER1']) and pd.isnull(row['OWNER2']):\n",
    "        return None\n",
    "    elif pd.isnull(row['OWNER1']) and not pd.isnull(row['OWNER2']):\n",
    "        return row['OWNER2']\n",
    "    elif not pd.isnull(row['OWNER1']) and pd.isnull(row['OWNER2']):\n",
    "        return row['OWNER1']\n",
    "    elif starts_with_preposition(row['OWNER2']):\n",
    "        return row['OWNER1'] + ' ' + row['OWNER2']\n",
    "    else:\n",
    "        return row['OWNER2'] + '; ' + row['OWNER1']\n",
    "    \n",
    "# apply the combine_owners function to the land_gdf dataframe\n",
    "land_gdf['OWNER'] = land_gdf.apply(combine_owners, axis=1)\n",
    "\n",
    "# if OWNER is 'PHILADELPHIA HOUSING AUTH' or 'PHILA HOUSING AUTHORITY', replace with 'PHILADELPHIA HOUSING AUTHORITY'\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'PHILADELPHIA HOUSING AUTH', 'OWNER'] = 'PHILADELPHIA HOUSING AUTHORITY'\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'PHILA HOUSING AUTHORITY', 'OWNER'] = 'PHILADELPHIA HOUSING AUTHORITY'\n",
    "\n",
    "# redevelopment authority typos\n",
    "redev_owner_variations = ['REDEVELOPMENT AUTHORITY OF PHILA', 'PHILA REDEVELOPMENT AUTH',\n",
    "'REDEVELOPMENT AUTHORITY O', 'PHILADELPHIA REDEVELOPMEN',\n",
    "'PHILA REDEVELOPMENT AUTHO', 'REDEVELOPMENT AUTHORITY',\n",
    "'REDEVELOPMENT AUTH']\n",
    "\n",
    "for var in redev_owner_variations:\n",
    "    land_gdf.loc[land_gdf['OWNER'] == var, 'OWNER'] = 'REDEVELOPMENT AUTHORITY OF PHILADELPHIA'\n",
    "\n",
    "# department of public property typos\n",
    "dpp_owner_variations = ['DEPT OF PUBLIC PROPERTY', 'DEPT OF PUBLIC PROPERT', 'DEPT OF PUBLC PROP; CITY OF PHILA',\n",
    "                        'DEPT OF PUBLIC PROP; CITY OF PHILA', 'DEPT OF PUBLIC PROPERTY; CITY OF PHILA', 'DEPT PUB PROP; CITY OF PHILA',\n",
    "                        'DEPT OF PUB PROP; CITY OF PHILA', 'DEP OF PUB PROP; CITY OF PHILA', 'DEPT OF PUBLIC PROP; CITY OF PHILADELPHIA',\n",
    "                        'DEPT PUBLIC PROP R E DIV; CITY OF PHILA', 'PUBLIC PROP DIV; CITY OF PHILA', 'PUBLIC PROP REAL ESTATE; CITY OF PHILA',\n",
    "                        'REAL ESTATE DIV; CITY OF PHILA', 'REAL ESTATE DIVISION; CITY OF PHILA']\n",
    "\n",
    "for var in dpp_owner_variations:\n",
    "    land_gdf.loc[land_gdf['OWNER'] == var, 'OWNER'] = 'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY'\n",
    "\n",
    "# HUD\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'URBAN DEVELOPMENT; SECRETARY OF HOUSING', 'OWNER'] = 'SECRETARY OF HOUSING AND URBAN DEVELOPMENT'\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'URBAN DEVELOPMENT; SECRETARY OF HOUSING AND', 'OWNER'] = 'SECRETARY OF HOUSING AND URBAN DEVELOPMENT'\n",
    "\n",
    "# commonwealth of pennsylvania\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'COMMONWEALTH OF PA', 'OWNER'] = 'COMMONWEALTH OF PENNSYLVANIA'\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'COMMONWEALTH OF PENNA', 'OWNER'] = 'COMMONWEALTH OF PENNSYLVANIA'\n",
    "\n",
    "# phdc\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'DEVELOPMENT CORPORATION; PHILADELPHIA HOUSING', 'OWNER'] = 'PHILADELPHIA HOUSING DEVELOPMENT CORPORATION'\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'PHILA HOUSING DEV CORP', 'OWNER'] = 'PHILADELPHIA HOUSING DEVELOPMENT CORPORATION'\n",
    "\n",
    "# PennDOT\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'DEPARTMENT OF TRANSPORTAT; COMMONWEALTH OF PENNSYLVA', 'OWNER'] = 'PENNDOT'\n",
    "\n",
    "# city of Philadelphia\n",
    "land_gdf.loc[land_gdf['OWNER'] == 'CITY OF PHILADELPHIA', 'OWNER'] = 'CITY OF PHILA'\n",
    "\n",
    "\n",
    "public_owners = ['PHILADELPHIA LAND BANK',\n",
    "                'PHILADELPHIA HOUSING AUTH',\n",
    "                'CITY OF PHILA',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'CITY OF PHILADELPHIA',\n",
    "                'DEPT OF PUBLC PROP; CITY OF PHILA',\n",
    "                'DEPT OF PUBLIC PROP; CITY OF PHILA',\n",
    "                'DEPT PUB PROP; CITY OF PHILA',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILA',\n",
    "                'PHILA REDEVELOPMENT AUTH',\n",
    "                'PHILADELPHIA LAND INVESTM',\n",
    "                'REDEVELOPMENT AUTHORITY O',\n",
    "                'PHILADELPHIA REDEVELOPMEN',\n",
    "                'PHILA HOUSING AUTHORITY',\n",
    "                'KENSINGTON HOUSING AUTHOR',\n",
    "                'DEVELOPMENT CORPORATION; PHILADELPHIA HOUSING',\n",
    "                'PHILA REDEVELOPMENT AUTHO',\n",
    "                'DEPT OF PUB PROP; CITY OF PHILA',\n",
    "                'PHILA HOUSING DEV CORP',\n",
    "                'DEP OF PUB PROP; CITY OF PHILA',\n",
    "                'REDEVELOPMENT AUTHORITY',\n",
    "                'COMMONWEALTH OF PA',\n",
    "                'COMMONWEALTH OF PENNA',\n",
    "                'DEPT OF PUBLIC PROP; CITY OF PHILADELPHIA',\n",
    "                'DEPT PUBLIC PROP R E DIV; CITY OF PHILA',\n",
    "                'PUBLIC PROP DIV; CITY OF PHILA',\n",
    "                'PUBLIC PROP REAL ESTATE; CITY OF PHILA',\n",
    "                'REAL ESTATE DIV; CITY OF PHILA',\n",
    "                'REAL ESTATE DIVISION; CITY OF PHILA',\n",
    "                'URBAN DEVELOPMENT; SECRETARY OF HOUSING'\n",
    "                'URBAN DEVELOPMENT; SECRETARY OF HOUSING AND',\n",
    "                'PHILADELPHIA REDEVELOPMENT AUTHORITY',\n",
    "                'PHILADELPHIA REDEVELOPMENT AUTH',\n",
    "                'PHILADELPHIA HOUSING AUTHORITY',\n",
    "                'PHILADELPHIA LAND BANK',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'PHILADELPHIA HOUSING AUTHORITY',\n",
    "                'CITY OF PHILADELPHIA',\n",
    "                'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'PHILADELPHIA LAND INVESTMENT',\n",
    "                'PHILADELPHIA REDEVELOPMENT AUTHORITY',\n",
    "                'PHILADELPHIA HOUSING AUTHORITY',\n",
    "                'KENSINGTON HOUSING AUTHORITY',\n",
    "                'PHILADELPHIA HOUSING DEVELOPMENT CORPORATION',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY',\n",
    "                'PHILADELPHIA HOUSING DEVELOPMENT CORPORATION',\n",
    "                'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'COMMONWEALTH OF PENNSYLVANIA',\n",
    "                'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY',\n",
    "                'SECRETARY OF HOUSING AND URBAN DEVELOPMENT',\n",
    "                'REDEVELOPMENT AUTHORITY OF PHILADELPHIA',\n",
    "                'PHILADELPHIA LAND INVESTMENT',\n",
    "                'CITY OF PHILADELPHIA DEPARTMENT OF PUBLIC PROPERTY',\n",
    "                'PENNDOT'\n",
    "]\n",
    "\n",
    "# create a new column called 'public_owner' that is True if the OWNER column is in the public_owners list\n",
    "land_gdf['public_owner'] = land_gdf['OWNER'].isin(public_owners)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vacant Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the Vacant_Indicators_Bldg feature service\n",
    "bldg_url = 'https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/Vacant_Indicators_Bldg/FeatureServer/0/query'\n",
    "\n",
    "# Define the parameters for the Vacant_Indicators_Bldg API request\n",
    "bldg_params = {\n",
    "    'where': '1=1',\n",
    "    'outFields': '*',\n",
    "    'returnGeometry': 'true',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "# Make the Vacant_Indicators_Bldg API request\n",
    "bldg_response = requests.get(bldg_url, params=bldg_params)\n",
    "\n",
    "# Check if the Vacant_Indicators_Bldg request was successful\n",
    "if bldg_response.status_code == 200:\n",
    "    # Convert the Vacant_Indicators_Bldg JSON data to a geopandas geodataframe\n",
    "    bldg_data = bldg_response.json()\n",
    "\n",
    "    # convert the JSON data to a pandas dataframe\n",
    "    bldg_df = pd.DataFrame(bldg_data['features'])\n",
    "\n",
    "    # separate the attributes column into one column per attribute\n",
    "    bldg_df = pd.concat([bldg_df.drop(['attributes'], axis=1), bldg_df['attributes'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # make the `geometry` column a shapely geometry object\n",
    "    bldg_df['geometry'] = bldg_df['geometry'].apply(lambda x: Polygon(x['rings'][0]))\n",
    "\n",
    "    # convert the pandas dataframe to a geopandas geodataframe\n",
    "    bldg_gdf = gpd.GeoDataFrame(bldg_df, geometry='geometry', crs='EPSG:2272')\n",
    "\n",
    "else:\n",
    "    print('Vacant_Indicators_Bldg Request failed with status code:', bldg_response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PHS Community Landcare Parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the Vacant_Indicators_phs_landcare feature service\n",
    "phs_landcare_url = 'https://services.arcgis.com/fLeGjb7u4uXqeF9q/ArcGIS/rest/services/PHS_CommunityLandcare/FeatureServer/0/query'\n",
    "\n",
    "# Define the parameters for the Vacant_Indicators_phs_landcare API request\n",
    "phs_landcare_params = {\n",
    "    'where': '1=1',\n",
    "    'outFields': '*',\n",
    "    'returnGeometry': 'true',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "# Make the Vacant_Indicators_phs_landcare API request\n",
    "phs_landcare_response = requests.get(phs_landcare_url, params=phs_landcare_params)\n",
    "\n",
    "# Check if the Vacant_Indicators_phs_landcare request was successful\n",
    "if phs_landcare_response.status_code == 200:\n",
    "    # Convert the Vacant_Indicators_phs_landcare JSON data to a geopandas geodataframe\n",
    "    phs_landcare_data = phs_landcare_response.json()\n",
    "\n",
    "    # convert the JSON data to a pandas dataframe\n",
    "    phs_landcare_df = pd.DataFrame(phs_landcare_data['features'])\n",
    "\n",
    "    # separate the attributes column into one column per attribute\n",
    "    phs_landcare_df = pd.concat([phs_landcare_df.drop(['attributes'], axis=1), phs_landcare_df['attributes'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # make the `geometry` column a shapely geometry object\n",
    "    phs_landcare_df['geometry'] = phs_landcare_df['geometry'].apply(lambda x: Polygon(x['rings'][0]))\n",
    "\n",
    "    # convert the pandas dataframe to a geopandas geodataframe\n",
    "    phs_landcare_gdf = gpd.GeoDataFrame(phs_landcare_df, geometry='geometry', crs='EPSG:2272')\n",
    "\n",
    "else:\n",
    "    print('PHS_CommunityLandcare Request failed with status code:', phs_landcare_response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import two more datasets from the City's Carto database (SQL)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. L&I Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "# Calculate one year ago from today's date\n",
    "one_year_ago = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create the SQL query\n",
    "li_sql_query = \"SELECT service_request_id, subject, status, service_name, service_code, lat, lon FROM public_cases_fc WHERE requested_datetime >= '{}'\".format(one_year_ago)\n",
    "\n",
    "# Make the GET request\n",
    "li_response = requests.get(\"https://phl.carto.com/api/v2/sql\", params={\"q\": li_sql_query})\n",
    "\n",
    "# Get the data\n",
    "li_data = li_response.json()[\"rows\"]\n",
    "\n",
    "# convert li_data to a pandas dataframe\n",
    "li_df = pd.DataFrame(li_data)\n",
    "\n",
    "# Convert the data to a geopandas dataframe\n",
    "li_gdf = gpd.GeoDataFrame(li_df, geometry=gpd.points_from_xy(li_df.lon, li_df.lat), crs='EPSG:2272')\n",
    "\n",
    "# drop the lat and lon columns\n",
    "li_gdf.drop(['lat', 'lon'], axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining to pull in:\n",
    "1. Council Districts\n",
    "2. Neighborhoods\n",
    "3. RCOs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gun Crimes\n",
    "\n",
    "For our gun crime kernel density estimate, we have two steps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import gun crime data from the City's Carto database (SQL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the SQL query\n",
    "guncrimes_sql_query = \"SELECT text_general_code, dispatch_date, point_x, point_y FROM incidents_part1_part2 WHERE dispatch_date_time >= '{}' AND text_general_code\".format(one_year_ago)\n",
    "\n",
    "# Make the GET request\n",
    "guncrimes_response = requests.get(\"https://phl.carto.com/api/v2/sql\", params={\"q\": guncrimes_sql_query})\n",
    "\n",
    "# Get the data\n",
    "guncrimes_data = guncrimes_response.json()[\"rows\"]\n",
    "\n",
    "# convert guncrimes_data to a pandas dataframe\n",
    "guncrimes_df = pd.DataFrame(guncrimes_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_general_code</th>\n",
       "      <th>dispatch_date</th>\n",
       "      <th>point_x</th>\n",
       "      <th>point_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thefts</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>-75.247645</td>\n",
       "      <td>39.886841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thefts</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>-75.046249</td>\n",
       "      <td>40.033620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thefts</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>-75.046249</td>\n",
       "      <td>40.033620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thefts</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>-75.046249</td>\n",
       "      <td>40.033620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thefts</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>-75.046249</td>\n",
       "      <td>40.033620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_general_code dispatch_date    point_x    point_y\n",
       "0            Thefts    2022-08-22 -75.247645  39.886841\n",
       "1            Thefts    2022-09-10 -75.046249  40.033620\n",
       "2            Thefts    2022-09-09 -75.046249  40.033620\n",
       "3            Thefts    2022-09-09 -75.046249  40.033620\n",
       "4            Thefts    2022-09-07 -75.046249  40.033620"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guncrimes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the data to a geopandas dataframe\n",
    "guncrimes_gdf = gpd.GeoDataFrame(guncrimes_df, geometry=gpd.points_from_xy(guncrimes_df.point_x, guncrimes_df.point_y), crs='EPSG:2272')\n",
    "\n",
    "# drop the lat and lon columns\n",
    "guncrimes_gdf.drop(['point_x', 'point_y'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a kernel density estimate from the gun crime data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get X and Y coordinates of well points\n",
    "x_sk = guncrime_gdf[\"geometry\"].x\n",
    "y_sk = guncrime_gdf[\"geometry\"].y\n",
    "\n",
    "# Get minimum and maximum coordinate values of well points\n",
    "min_x_sk, min_y_sk, max_x_sk, max_y_sk = guncrime_gdf.total_bounds\n",
    "\n",
    "# Create a cell mesh grid\n",
    "# Horizontal and vertical cell counts should be the same\n",
    "XX_sk, YY_sk = np.mgrid[min_x_sk:max_x_sk:100j, min_y_sk:max_y_sk:100j]\n",
    "\n",
    "# Create 2-D array of the coordinates (paired) of each cell in the mesh grid\n",
    "positions_sk = np.vstack([XX_sk.ravel(), YY_sk.ravel()]).T\n",
    "\n",
    "# Create 2-D array of the coordinate values of the well points\n",
    "Xtrain_sk = np.vstack([x_sk, y_sk]).T\n",
    "\n",
    "# Get kernel density estimator (can change parameters as desired)\n",
    "kde_sk = KernelDensity(bandwidth = 5280, metric = 'euclidean', kernel = 'gaussian', algorithm = 'auto')\n",
    "\n",
    "# Fit kernel density estimator to wells coordinates\n",
    "kde_sk.fit(Xtrain_sk)\n",
    "\n",
    "# Evaluate the estimator on coordinate pairs\n",
    "Z_sk = np.exp(kde_sk.score_samples(positions_sk))\n",
    "\n",
    "# Reshape the data to fit mesh grid\n",
    "Z_sk = Z_sk.reshape(XX_sk.shape)\n",
    "\n",
    "# Plot data\n",
    "#fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "#ax.imshow(np.rot90(Z_sk), cmap = \"RdPu\", extent = [min_x_sk, max_x_sk, min_y_sk, max_y_sk])\n",
    "#ax.plot(x_sk, y_sk, 'k.', markersize = 2, alpha = 0.1)\n",
    "#plt.show()\n",
    "\n",
    "import rasterio\n",
    "\n",
    "def export_kde_raster(Z, XX, YY, min_x, max_x, min_y, max_y, proj, filename):\n",
    "    '''Export and save a kernel density raster.'''\n",
    "\n",
    "    # Flip array vertically and rotate 270 degrees\n",
    "    Z_export = np.rot90(np.flip(Z, 0), 3)\n",
    "\n",
    "    # Get resolution\n",
    "    xres = (max_x - min_x) / len(XX)\n",
    "    yres = (max_y - min_y) / len(YY)\n",
    "\n",
    "    # Set transform\n",
    "    transform = rasterio.Affine.translation(min_x - xres / 2, min_y - yres / 2) * rasterio.Affine.scale(xres, yres)\n",
    "\n",
    "    # Export array as raster\n",
    "    with rasterio.open(\n",
    "            filename,\n",
    "            mode = \"w\",\n",
    "            driver = \"GTiff\",\n",
    "            height = Z_export.shape[0],\n",
    "            width = Z_export.shape[1],\n",
    "            count = 1,\n",
    "            dtype = Z_export.dtype,\n",
    "            crs = proj,\n",
    "            transform = transform,\n",
    "    ) as new_dataset:\n",
    "            new_dataset.write(Z_export, 1)\n",
    "\n",
    "# Export raster\n",
    "export_kde_raster(Z = Z_sk, XX = XX_sk, YY = YY_sk,\n",
    "                  min_x = min_x_sk, max_x = max_x_sk, min_y = min_y_sk, max_y = max_y_sk,\n",
    "                  proj = 2272, filename = \"C:/Users/Nissim/Desktop/Vacant Lots Project/guncrime_kde_rast.tif\")\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "kde_rast = rasterio.open(\"C:/Users/Nissim/Desktop/Vacant Lots Project/guncrime_kde_rast.tif\")\n",
    "\n",
    "from rasterio.plot import show\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify data into percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterstats\n",
    "\n",
    "vac_lots_gdf3['rast_val'] = rasterstats.point_query(vac_lots_gdf3, \"C:/Users/Nissim/Desktop/Vacant Lots Project/guncrime_kde_rast.tif\")\n",
    "\n",
    "import mapclassify\n",
    "\n",
    "# Define the number of classes\n",
    "n_classes = 10\n",
    "\n",
    "# Create a quantiles classifier\n",
    "classifier = mapclassify.Quantiles.make(k = n_classes)\n",
    "\n",
    "# Classify the data\n",
    "vac_lots_gdf3['rast_val'] = vac_lots_gdf3[['rast_val']].apply(classifier)\n",
    "\n",
    "# scale from 1-5 instead of 0-4\n",
    "vac_lots_gdf3['rast_val'] = vac_lots_gdf3['rast_val'].replace([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], ['90th Percentile', '80th Percentile', '70th Percentile', '60th Percentile', '50th Percentile', '40th Percentile', '30th Percentile', '20th Percentile', '10th Percentile', '0th Percentile'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vac_props_guncrime_dash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e6f34d5c18e199cb03cbea79929a02f010c80f88137b286b7b082b5a9d350f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
